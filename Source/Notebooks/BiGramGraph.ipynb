{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx          as nx\n",
    "import seaborn           as sns\n",
    "from nltk                import ngrams\n",
    "from pyvis.network       import Network\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pydot\n",
    "import spacy as sp\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from wordcloud import STOPWORDS\n",
    "from string import punctuation\n",
    "import enchant\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "wchecker = enchant.Dict(\"en_US\")\n",
    "nlps = sp.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGramGraph:\n",
    "    \"\"\"\n",
    "    A class used to transform a corpus given as a numpy array into a graph form of the\n",
    "    2-gram representation.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    Graph : nx.Graph\n",
    "        The Graph Representation of The Ngram Input.\n",
    "    N_nodes : int\n",
    "        Number of Nodes in Graph.\n",
    "    Data : pandas DataFrame\n",
    "        A Pandas DataFrame containing all words thier color label and POS and ENT tags if appropriate method is called prior.\n",
    "    Edges : pandas DataFrame\n",
    "        A Pandas DataFrame containing all edges and thier weights.    \n",
    "    Name : str\n",
    "        The name given to a graph (Usually to mark it with the name of its corresponding corpus).\n",
    "    N_edges : int\n",
    "        Number of Edges in Graph.\n",
    "    In_Max_Deg : int\n",
    "        Maximum In Degree in Graph.\n",
    "    Out_Max_Deg : int\n",
    "        Maximum Out Degree in Graph.\n",
    "    In_Min_Deg : int\n",
    "        Minimum In Degree in Graph.\n",
    "    Out_Min_Deg : int\n",
    "        Minimum Out Degree in Graph.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data=None,prebuild=None, notebook=False):\n",
    "        \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        data : list\n",
    "            a list of texts to be converted into a BiGram Graph\n",
    "        prebuild : list\n",
    "            if prebuild is used than the bigram graph is constructed using the passed in list that sholud\n",
    "            contain all elements that make up a bigram graph, mainly used in graph duplication and dumping as binary file.\n",
    "        notebook : boolean\n",
    "            if set to True then any resources loaded that are compatable with notebook instances will be adapted to notebook mode.\n",
    "        \n",
    "        Returns a BiGram-Graph representation of a given set of texts \n",
    "        return: A generator of cycles\n",
    "        \"\"\"\n",
    "        if prebuild != None:\n",
    "                self.Graph        = prebuild[0]\n",
    "                self.N_nodes      = prebuild[1]\n",
    "                self.N_edges      = prebuild[2]\n",
    "                self.In_Max_Deg   = prebuild[3]\n",
    "                self.Out_Max_Deg  = prebuild[4]\n",
    "                self.In_Min_Deg   = prebuild[5]\n",
    "                self.Out_Min_Deg  = prebuild[6]\n",
    "                self.Data         = prebuild[7]\n",
    "                self.Name         = prebuild[8]\n",
    "                self.Edges        = prebuild[9]\n",
    "        else:\n",
    "            if not notebook:\n",
    "                from tqdm import tqdm\n",
    "                tqdm.pandas()\n",
    "            else:\n",
    "                from tqdm.notebook import tqdm\n",
    "                tqdm.pandas()\n",
    "            \n",
    "            #merge text into a singal body and calculate bigram \n",
    "            tokenized_text = ' '.join(data).split()\n",
    "            ngram = ngrams(tokenized_text, n=2)\n",
    "            ngram = list(ngram)\n",
    "            \n",
    "            #derive edge weights an unique words to be represented as nodes\n",
    "            n_frequencies = nltk.FreqDist(ngram)\n",
    "            edges = list(dict(n_frequencies).keys())\n",
    "            nodes = np.unique(np.array(edges).flatten())\n",
    "            \n",
    "            #initiate an instance of a directed graph  \n",
    "            self.Graph = nx.DiGraph()\n",
    "            self.Graph.add_nodes_from(nodes)\n",
    "            #Set graph edges according to bigram pairs\n",
    "            for x, y in edges:\n",
    "                self.Graph.add_edge(x, y, value=n_frequencies[(x, y)])\n",
    "            \n",
    "\n",
    "            # ===================Graph Attributes ==============================\n",
    "            self.N_nodes = len(nodes)\n",
    "            self.N_edges = len(edges)\n",
    "            self.In_Max_Deg = max(dict(self.Graph.in_degree).values())\n",
    "            self.Out_Max_Deg = max(dict(self.Graph.out_degree).values())\n",
    "            self.In_Min_Deg = min(dict(self.Graph.in_degree).values())\n",
    "            self.Out_Min_Deg = min(dict(self.Graph.out_degree).values())\n",
    "            self._nlp = None\n",
    "            self.Data = nx.algorithms.coloring.greedy_color(self.Graph)\n",
    "            self.Data = pd.DataFrame([self.Data.values(),\n",
    "                                      self.Data.keys()]).T.rename(columns={0: 'color', 1: 'word'})\n",
    "            self.Name='Default Name'\n",
    "\n",
    "            self.Edges = pd.DataFrame(edges, columns=['in', 'out'])\n",
    "            self.Edges['weight'] = self.Edges.apply(lambda _z: n_frequencies[(_z['in'], _z['out'])], axis=1)\n",
    "            # =================================================================\n",
    "            \n",
    "            \n",
    "    def add_part_of_speech(self):\n",
    "        \"\"\"\n",
    "        Use spacy to extract part of speech tag for each node and append it to the \"Data\" attribute.\n",
    "        \"\"\"\n",
    "        import spacy as sp\n",
    "        self._nlp = sp.load('en_core_web_sm')\n",
    "        self.Data['pos'] = self.Data['word'].progress_apply(lambda _z: self._nlp(str(_z))[0].pos_)\n",
    "        \n",
    "    def add_entities_of_speech(self):\n",
    "        \"\"\"\n",
    "        Use spacy to extract part of speech tag for each node and append it to the \"Data\" attribute.\n",
    "        \"\"\"\n",
    "        import spacy as sp\n",
    "        self._nlp = sp.load('en_core_web_sm')\n",
    "        def get_ent(_z):\n",
    "            t = self._nlp(str(_z)).ents\n",
    "            if len(t)>0:\n",
    "                return t[0].label_\n",
    "            else:\n",
    "                return 'NaN'\n",
    "        self.Data['ent'] = self.Data['word'].progress_apply(get_ent)\n",
    "\n",
    "    def get_Xi(self) -> int:\n",
    "        \"\"\"\n",
    "        :return: The chromatic number of the graph.\n",
    "        \"\"\"\n",
    "        return len(self.Data['color'].unique())\n",
    "    \n",
    "    def is_DAG(self):\n",
    "        \"\"\"\n",
    "        Check if a BiGramGraph represent a directed acyclic graph\n",
    "        return: Boolean: True if the graph is DAG else False\n",
    "        \"\"\"\n",
    "        return nx.algorithms.dag.is_directed_acyclic_graph(self.Graph)\n",
    "    def get_Diameter(self):\n",
    "        \"\"\"\n",
    "        Returns the diameter of the graph\n",
    "        return: Int: Diameter of the graph\n",
    "        \"\"\"\n",
    "        return nx.algorithms.distance_measures.diameter(self.Graph)\n",
    "    \n",
    "    def get_Min_Edge_Cover(self):\n",
    "        \"\"\"\n",
    "        Returns the minimum edge cover of the graph\n",
    "        return: \n",
    "        \"\"\"\n",
    "        return nx.algorithms.covering.min_edge_cover(self.Graph)\n",
    "    \n",
    "    def get_Shortest_Simple_Path(self,start_node,end_node):\n",
    "        \"\"\"\n",
    "          Attributes\n",
    "        ----------\n",
    "        start_node : str\n",
    "            the node from which the path starts\n",
    "        end_node : str\n",
    "            the node at which the path ends\n",
    "               \n",
    "        Returns the shortest simple path between two words\n",
    "        return: list: shortest path between two nodes\n",
    "        \"\"\"\n",
    "        return nx.algorithms.simple_paths.shortest_simple_paths(self.Graph,source=start_node,target=end_node)\n",
    "    \n",
    "    def get_Eulerian(self):\n",
    "        \"\"\"\n",
    "               \n",
    "        Returns an euler graph if the given bigram garph is eulerian\n",
    "        return: network x Graph: euler graph\n",
    "        \"\"\"\n",
    "        if nx.is_eulerian(self.Graph):\n",
    "            return nx.eulerian_circuit()(self.Graph)\n",
    "        else:\n",
    "            return 'Not Eulerian'\n",
    "        \n",
    "    def get_Volume(self,S):\n",
    "        \n",
    "        return nx.algorithms.cuts.volume(self.Graph,S)\n",
    "    \n",
    "    def get_Cycle(self,start_node):\n",
    "        \"\"\"\n",
    "          Attributes\n",
    "        ----------\n",
    "        start_node : str\n",
    "            the node from which the cycle starts\n",
    "\n",
    "               \n",
    "        Returns the cycle starting at a given word\n",
    "        return: list: cycle starting at a given word\n",
    "        \"\"\"\n",
    "        return nx.algorithms.cycles.find_cycle(self.Graph,start_node)\n",
    "    \n",
    "    def get_All_Unique_Cycles(self):\n",
    "        \"\"\"\n",
    "        Returns all unique simple cycles contained inside the graph\n",
    "        return: List of list where each inner list contains a sequence of nodes representing a cycle\n",
    "        \"\"\"\n",
    "        hash_list = []\n",
    "        unique_cycle = []\n",
    "        for i in tqdm(range(self.N_nodes),leave=False):\n",
    "            cyclye = self.get_Cycle(self.Data.word[i])\n",
    "            c_hash = hash(str(self.get_Cycle(self.Data.word[i])))\n",
    "            if c_hash not in hash_list:\n",
    "                hash_list.append(c_hash)\n",
    "                unique_cycle.append(cyclye)\n",
    "        return unique_cycle\n",
    "    def get_All_Simple_Cycles(self):\n",
    "        \"\"\"\n",
    "        Returns a generator which output simple cycles \n",
    "        return: A generator of cycles\n",
    "        \"\"\"\n",
    "        return nx.algorithms.cycles.simple_cycles(self.Graph)\n",
    "    \n",
    "    def get_Shortest_Path(self,source,target,weight=None,method='dijkstra'):\n",
    "        \"\"\"\n",
    "          Attributes\n",
    "        ----------\n",
    "        source : str\n",
    "            the node from which the path starts\n",
    "        target : str\n",
    "            the node at which the path ends   \n",
    "        Returns the shortest path between two words\n",
    "        return: list: path between two nodes\n",
    "        \"\"\"\n",
    "        return nx.shortest_path(bigraph_models[0].Graph, source=source, target=target, weight=weight, method=method)\n",
    "    \n",
    "    def is_Strongly_Connected(self):\n",
    "        return nx.algorithms.components.is_strongly_connected(self.Graph)\n",
    "    def get_Number_Strongly_Connected_Components(self):\n",
    "        return nx.algorithms.components.number_strongly_connected_components(self.Graph)\n",
    "    def get_Strongly_Connected_Components(self):\n",
    "        return nx.algorithms.components.strongly_connected_components(self.Graph)\n",
    "    def remove_self_loops(self):\n",
    "        self.Graph.remove_edges_from(nx.selfloop_edges(self.Graph))\n",
    "    def extract_K_Core(self,K=None,notebook=False):\n",
    "        \"\"\"\n",
    "          Attributes\n",
    "        ----------\n",
    "        K : int\n",
    "            the degree of weights in the K core extracted\n",
    "        notebook : boolean\n",
    "            the mode of the returend graph similar to the class constructor\n",
    "        Returns the K core of the graph\n",
    "        return: BiGramGraph: K core of graph\n",
    "        \"\"\"\n",
    "        K_CORE = nx.algorithms.core.k_core(self.Graph,k=K)\n",
    "        attributes = []\n",
    "        # ===================Graph Attributes ==============================\n",
    "        attributes.append(K_CORE) #Graph\n",
    "        attributes.append(K_CORE.number_of_nodes())\n",
    "        attributes.append(K_CORE.number_of_edges())\n",
    "        attributes.append(max(dict(K_CORE.in_degree).values()))\n",
    "        attributes.append(max(dict(K_CORE.out_degree).values()))\n",
    "        attributes.append(min(dict(K_CORE.in_degree).values()))\n",
    "        attributes.append(min(dict(K_CORE.out_degree).values()))\n",
    "        #Data = nx.algorithms.coloring.greedy_color(K_CORE)\n",
    "        nodes = list(K_CORE.nodes())\n",
    "\n",
    "        Data = self.Data.set_index('word').loc[nodes].reset_index()\n",
    "        #Data['color'] = self.Data.set_index('word').loc[nodes].reset_index().color\n",
    "        #Data = Data[['color','word']]\n",
    "        attributes.append(Data)\n",
    "        attributes.append(self.Name)\n",
    "        \n",
    "        weights = dict(K_CORE.edges)#[('empty','street')]['value']\n",
    "\n",
    "        Edges = pd.DataFrame(list(weights.keys()), columns=['in', 'out'])\n",
    "\n",
    "        Edges['weight'] = Edges.apply(lambda _z: weights[(_z['in'], _z['out'])]['value'], axis=1)\n",
    "        attributes.append(Edges)\n",
    "            # =================================================================\n",
    "  \n",
    "\n",
    "        return  BiGramGraph(prebuild=attributes,notebook=notebook)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        n = self.N_nodes\n",
    "        e = self.N_edges\n",
    "        xi = self.get_Xi()\n",
    "        return f'Number of words included: {n}\\nNumber of edges included: {e}\\nChromatic number: {xi}\\n'\n",
    "\n",
    "    def __getitem__(self, item) -> dict:\n",
    "        return dict()\n",
    "\n",
    "    def vectorize(self, string, method='chromatic',seq_length=None,pad_with=None,strategy=None):\n",
    "         \"\"\"\n",
    "          Attributes\n",
    "        ----------\n",
    "        string : str\n",
    "            the target text to be vectroized\n",
    "        method : str\n",
    "            the method by which the text is vectorized , deafult is chromatic.\n",
    "            methods include currently only chromatic vectorization\n",
    "        seq_length : int\n",
    "            the length of the vectorized output usually set to the maximum length string in a corpus\n",
    "        pad_with : int\n",
    "            the number with which the vectorizer will pad missing words only work when strategy argument is set to \"pad_with\"\n",
    "        strategy : str\n",
    "            which strategy sholud the vectorizer use when dealing with missing value currently only \"pad_with\" is supported\n",
    "            \n",
    "        Returns the vectorized version of the given string\n",
    "        return: np.darray: vectorized text\n",
    "        \"\"\"\n",
    "            \n",
    "        if method == 'chromatic':\n",
    "            if type(string) == str:\n",
    "                if strategy == None:\n",
    "                    vectorized = np.zeros(len(string))\n",
    "                    for idx,word in enumerate(string.split(' ')):\n",
    "                        query = self.Data.query(f'word == \"{word}\"').color.values\n",
    "                        if len(query) == 0:\n",
    "                            vectorized[idx] = float('nan')\n",
    "                        else:\n",
    "                            vectorized[idx] = query[0]+1\n",
    "                    return vectorized\n",
    "                elif strategy == 'pad_with':\n",
    "                    vectorized = (np.ones(max(len(string.split(' ')),seq_length))*pad_with)\n",
    "                    for idx,word in enumerate(string.split(' ')):\n",
    "                        query = self.Data.query(f'word == \"{word}\"').color.values\n",
    "                        if len(query) == 0:\n",
    "                            vectorized[idx] = float('nan')\n",
    "                        else:\n",
    "                            vectorized[idx] = query[0]+1\n",
    "                    return vectorized\n",
    "                else:\n",
    "                    raise BadStrategy('bad strategy')\n",
    "            elif type(string) in [list,np.ndarray,pd.Series]:\n",
    "                \n",
    "                if strategy == 'pad_with':\n",
    "                    \n",
    "                    vectorized = (np.ones(len(string),max(len(string),seq_length))*pad_with)\n",
    "                                        \n",
    "                    for kdx,sentence in enumerate(string):\n",
    "                        for idx,word in enumerate(sentence.split(' ')):\n",
    "                            query = self.Data.query(f'word == \"{word}\"').color.values\n",
    "                            if len(query) == 0:\n",
    "                                vectorized[kdx,idx] = float('nan')\n",
    "                            else:\n",
    "                                vectorized[kdx,idx] = query[0]+1\n",
    "                    return vectorized\n",
    "                else:\n",
    "                    raise BadStrategy('bad strategy')\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            raise NameError('Bad Method')\n",
    "            \n",
    "    def dump(self):\n",
    "        \"\"\"\n",
    "        Returns a list of all graph components which can be pickled and than reconstructen using the prebuild argument\n",
    "        of the class constructor\n",
    "        return: list: all elements that make up a bigram graph instance\n",
    "        \"\"\"\n",
    "        return [self.Graph,\n",
    "                self.N_nodes,\n",
    "                self.N_edges,\n",
    "                self.In_Max_Deg,\n",
    "                self.Out_Max_Deg,\n",
    "                self.In_Min_Deg,\n",
    "                self.Out_Min_Deg,\n",
    "                self.Data,\n",
    "                self.Name,\n",
    "                self.Edges\n",
    "               ]\n",
    "\n",
    "\n",
    "    def Viz_Graph(self, notebook=False, height=500, width=900, directed=False):\n",
    "        \"\"\"\n",
    "        Returns an html file create via graphviz that represents the graph\n",
    "        return: html: graph vizualization\n",
    "        \"\"\"\n",
    "        nt = Network(f'{height}px', f'{width}px', notebook=notebook, directed=directed)\n",
    "        nt.set_options(\n",
    "            'var options = { \"physics\": {\"forceAtlas2Based\": {\"gravitationalConstant\": -230,\"springLength\": 170,\\\n",
    "              \"springConstant\": 0,\\\n",
    "              \"avoidOverlap\": 1\\\n",
    "            },\\\n",
    "            \"minVelocity\": 0.75,\\\n",
    "            \"solver\": \"forceAtlas2Based\",\\\n",
    "            \"timestep\": 1\\\n",
    "          }\\\n",
    "        }\\\n",
    "        ')\n",
    "        nt.from_nx(self.Graph)\n",
    "        # nt.show_buttons(filter_=['physics'])\n",
    "        nt.prep_notebook()\n",
    "        return nt.show('nx.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "\n",
    "def calculate_path_weight(Graph,path):\n",
    "    weight = 0\n",
    "    start = path[0]\n",
    "    for i in path[1:]:\n",
    "        weight += Graph.Edges[(Graph.Edges['in'] == start[0])&(Graph.Edges.out == i[0])].weight.values[0]\n",
    "        start =i\n",
    "    return weight\n",
    "\n",
    "def calculate_cycle_density(Graph,cycle):\n",
    "    weight = 0\n",
    "    for i in cycle:\n",
    "        weight += np.sqrt(Graph.Graph.out_degree(i[0])+Graph.Graph.in_degree(i[0]))\n",
    "    return weight    \n",
    "\n",
    "def calculate_path_density(Graph,path):\n",
    "    weight = 0\n",
    "    for i in path:\n",
    "        IN  = Graph.Graph.out_degree(i[0])\n",
    "        OUT = Graph.Graph.in_degree(i[0])\n",
    "        if type(IN)!=int:\n",
    "            weight += np.sqrt(OUT)\n",
    "        elif type(OUT) != int:\n",
    "            weight += np.sqrt(IN)\n",
    "        else:\n",
    "            weight+= np.sqrt(IN+OUT)\n",
    "    return weight \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaticRandomWalker:\n",
    "     \"\"\"\n",
    "    A class used to transform a corpus given as a numpy array into a graph form of the\n",
    "    2-gram representation.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Methods\n",
    "    ----------\n",
    "    generate : return a randomly generated sentence based on given arguments\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,Graph):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments\n",
    "        ----------\n",
    "        Graph : BiGramGraph the bigram graph based on which sentences will be generated\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Graph = Graph\n",
    "        self.max_xi    = Graph.get_Xi()\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.Graph.__repr__()\n",
    "        \n",
    "    def generate_chromatic_vector(self,max_xi,size):\n",
    "        chromatic_nums = list(range(max_xi))\n",
    "        last_num = -1\n",
    "        chrom_vec = []\n",
    "        for i in range(size):\n",
    "            index = np.floor((np.random.beta(1.5,1.5,1)*max_xi)[0])\n",
    "            cur_choice = chromatic_nums[int(index)]\n",
    "            while cur_choice == last_num:\n",
    "                index = np.floor((np.random.beta(6,2,1)*max_xi)[0])\n",
    "                cur_choice = chromatic_nums[int(index)]\n",
    "            if cur_choice != last_num:\n",
    "                last_num=cur_choice\n",
    "                chrom_vec.append(cur_choice)\n",
    "            else:\n",
    "                continue\n",
    "        self.Random_Chromatic_Vec = chrom_vec\n",
    "    def calculate_path_weight(self,path):\n",
    "        weight = 0\n",
    "        start = path[0]\n",
    "        for i in path[1:]:\n",
    "            weight += self.Graph.Edges[(self.Graph.Edges['in'] == start)&(self.Graph.Edges.out == i)].weight.values[0]\n",
    "            start =i\n",
    "        return weight\n",
    "    \n",
    "    def generate(self,method='heaviest',vec_size = 5, depth=10):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments\n",
    "        ----------\n",
    "        method : str\n",
    "            the protocl of path scoring via which the walker will choose its course available methods include:\n",
    "            1) heaviest -> the max weighted path\n",
    "            2) lightest -> the min weighted path\n",
    "            3) density_max -> the max density path\n",
    "            4) density_min -> the min density path\n",
    "        vec_size : int\n",
    "            the size of the randomly generated chromatic vector\n",
    "        depth : int\n",
    "            the maximum depth of search the walker will consider when choosing its next step\n",
    "\n",
    "            \n",
    "        \"\"\"\n",
    "        self.vec_size  = vec_size        \n",
    "        self.generate_chromatic_vector(self.max_xi,self.vec_size)\n",
    "        result = ' '\n",
    "        first_word   = self.Graph.Data[self.Graph.Data.color==self.Random_Chromatic_Vec[0]].sample(1).word.values[0]\n",
    "        for n in tqdm(self.Random_Chromatic_Vec[1:]):\n",
    "            #Calculate Best Path\n",
    "            paths = []\n",
    "            targets = self.Graph.Data[self.Graph.Data.color==n]\n",
    "            targets = targets.sample(depth if len(targets) >=depth else len(targets))\n",
    "            for target in tqdm(targets.word,leave=False):\n",
    "                gen = self.Graph.get_Shortest_Simple_Path(first_word,target)\n",
    "                paths.append(next(gen))\n",
    "            weights = np.array([self.calculate_path_weight(i) for i in paths])\n",
    "            if method == 'heaviest':\n",
    "                best_walk = paths[np.argmax(weights)]\n",
    "                first_word = targets.word.values[np.argmax(weights)]\n",
    "            elif method =='lightest':\n",
    "                best_walk = paths[np.argmin(weights)]\n",
    "                first_word = targets.word.values[np.argmin(weights)]\n",
    "            elif method =='density_max':\n",
    "                weights = [calculate_path_density(self.Graph,nltk.ngrams(i,2)) for i in paths]\n",
    "                best_walk = paths[np.argmax(weights)]\n",
    "                first_word = targets.word.values[np.argmax(weights)]\n",
    "            elif method =='density_min':\n",
    "                weights = [calculate_path_density(self.Graph,nltk.ngrams(i,2)) for i in paths]\n",
    "                best_walk = paths[np.argmin(weights)]\n",
    "                first_word = targets.word.values[np.argmin(weights)]\n",
    "            del weights\n",
    "            result += ' '.join(best_walk[:-1])+' '\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chromatic_distance(graph_1,graph_2):\n",
    "    \"\"\"\n",
    "      Args\n",
    "    ----------\n",
    "    graph_1 : BiGramGraph\n",
    "        the first graph to be compared against\n",
    "    graph_2 : BiGramGraph\n",
    "        the second graph to be compared against\n",
    "\n",
    "    Returns the psi similarity coeffiecnt as presented in the paper\n",
    "    return: int : psi similarity coeffiecnt\n",
    "    \"\"\"\n",
    "    if 'pos' not in graph_1.Data.columns or   'pos' not in graph_2.Data.columns:\n",
    "        raise PosError('Please Calculate PartofSpeech for Each Graph')\n",
    "    \n",
    "    overlaping_words = set(graph_1.Data['word'])\n",
    "    overlaping_words = overlaping_words & set(graph_2.Data['word'])\n",
    "    \n",
    "    I = len(overlaping_words)\n",
    "     \n",
    "    chrom_ds = pd.DataFrame(index = list(overlaping_words))\n",
    "    chrom_ds['chrom1'] = graph_1.Data.set_index('word').loc[overlaping_words].color\n",
    "    chrom_ds['chrom2'] = graph_2.Data.set_index('word').loc[overlaping_words].color\n",
    "    same_chrom_num = chrom_ds.apply(lambda x: np.mean(x) == x[0] ,axis=1)\n",
    "    chrom_ds = chrom_ds[same_chrom_num].rename(columns={'chrom1':'color'}).drop(columns=['chrom2'])\n",
    "    \n",
    "    #Epsilon\n",
    "    E = 0\n",
    "    chrom_ds['weight1'] = chrom_ds.index.to_series().apply(lambda x:graph_1.Graph.degree(x) )\n",
    "    #graph_1.Data.set_index('word').loc[overlaping_words].pos\n",
    "    chrom_ds['weight2'] = chrom_ds.index.to_series().apply(lambda x:graph_2.Graph.degree(x) )\n",
    "    #same_weight = chrom_ds.apply(lambda x: np.max(x)<=2*np.min(x) ,axis=1)\n",
    "    same_weight = chrom_ds[['weight1','weight2']].apply(lambda x: np.mean(x) == x[0] ,axis=1)\n",
    "    same_weight = chrom_ds[same_weight]\n",
    "    \n",
    "    ICW = len(same_weight)\n",
    "    IC = len(chrom_ds)\n",
    "    \n",
    "    return IC/I\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
